# Step 21: 环境升级 — 10×10 Grid + 5×5 Vision

> 日期: 2026-02-08
> 状态: ✅ 完成

## 目标

升级默认环境，释放 PC/睡眠/空间记忆等沉睡子系统。

## 动机

之前所有闭环学习在 5×5 grid + 3×3 vision 上完成。这个环境太简单：
- 3×3 视野只有 9 像素、3 种值 → PC(预测编码)无冗余可压缩
- 25 个格子 → 海马空间记忆无用武之地
- 食物吃掉立刻重生 → 睡眠巩固反而过度固化旧位置

50 个脑区为 5×5 格子世界服务 = V12 发动机买菜。

## 环境变更

| 参数 | 旧值 | 新值 | 理由 |
|------|------|------|------|
| grid size | 10×10 | 10×10 | 保持不变 |
| vision_radius | 1 (3×3) | **2 (5×5)** | 25 像素, PC 有效 |
| n_food | 3 | **5** | 更丰富的觅食环境 |
| n_danger | 2 | **3** | 3% 密度, 可学习的回避挑战 |

## 脑自动缩放

| 区域 | 旧 (3×3) | 新 (5×5) | 缩放因子 |
|------|----------|----------|----------|
| LGN | ~30 | **~100** | ×3.3 (3 neurons/pixel × 25 pixels) |
| V1 | ~160 | **~447** | ×2.78 (vis_scale = 25/9) |
| dlPFC | ~135 | **~223** | ×1.67 (sqrt scaling) |
| 其余 | 不变 | 不变 | — |

## 解锁的沉睡子系统

| 功能 | 旧状态 | 新状态 | 理由 |
|------|--------|--------|------|
| 预测编码 (PC) | 禁用 | **启用** | 5×5 视野有效 (+0.121 优势, Step 15-B 验证) |
| 睡眠巩固 | 禁用 | **启用** | 100 格子, 遗忘是问题, 轻量巩固有益 |
| 回放缓冲 | 30 episodes | **50** | 更多位置 → 需要更多记忆 |
| 空间记忆 | EC grid cells 已有 | 自然受益 | 更大空间 → grid cell 编码更有意义 |

## 睡眠巩固参数调优

初始参数在 10×10 环境中过度巩固 (improvement -0.210)。经过 2 轮调优：

| 参数 | 初始值 | 最终值 | 理由 |
|------|--------|--------|------|
| wake_steps_before_sleep | 500 | **800** | 长间隔, 轻触式巩固 |
| sleep_nrem_steps | 20 | **15** | 极轻量, 防止过度固化 |
| sleep_positive_da | 0.38 | **0.35** | 仅略高于基线 0.3, 温和推动 |

## 结果对比

**5k 学习曲线 (Test 1):**
```
Early (0-1k):  safety=0.31, food=17, danger=38
Late (4-5k):   safety=0.47, food=17, danger=19
Improvement: +0.16 ✅ (5k 内正向学习)
```

**Learner vs Control (Test 2):**
```
Learner: food=43, danger=44, safety=0.49
Control: food=30, danger=36, safety=0.45
Advantage: +0.0023 ✅ (翻正, 学习有效)
```

**10k 长时训练 (Test 4):**
```
Early (1-2k):  safety=0.423
Late (9-10k):  safety=0.336
Improvement: -0.086 ⚠️ (长时退化, 信用分配瓶颈)
```

**15×15 超大环境 (Test 5, 7×7 vision):**
```
Early (0-1k):  safety=0.333
Late (2-3k):   safety=0.367
Improvement: +0.033 ✅ (可正向学习!)
Brain: V1=877, dlPFC=310, LGN=196 neurons
```

## 调优历程

| 轮次 | n_danger | sleep 间隔 | NREM 步 | DA | 5k improvement | 10k improvement |
|------|---------|-----------|---------|-----|---------------|-----------------|
| 1 | 4 | 500 | 20 | 0.38 | +0.03 | -0.210 |
| **2** | **3** | **800** | **15** | **0.35** | **+0.16** | **-0.086** |

## 暴露的瓶颈 (10k 退化)

10k 训练退化 -0.086 说明：
1. **信用分配被视觉噪声稀释**: 447 个 V1 神经元中 >90% 对动作选择无关，eligibility trace 被淹没
2. **D1 方向子群无竞争**: 强化一个方向不抑制其他 → 长期权重趋同
3. **awake replay 强度可能过高**: 5 passes × 每次食物 → 多次重复后过拟合特定 episode

→ 下一步: D1 侧向抑制 (Step 22) 和/或基因层参数优化 (Step 23)

## 回归测试: 29/29 CTest 全通过, 零回归

## 系统状态

```
50区域 · 自适应神经元数 (5×5 vision: ~900 neurons, 7×7: ~1500) · ~115投射
默认环境: 10×10 grid, 5×5 vision, 5 food, 3 danger
解锁: 预测编码(PC) + 睡眠巩固 + 50 episode 回放缓冲
5k learning: improvement +0.16, late safety 0.47
下一步: D1 侧向抑制 / 基因层参数搜索 / 信用分配改进
```
