# Step 25: DA-STDP 能力下限诊断 + IT 表征质量

> 日期: 2026-02-08
> 状态: ✅ 完成

## 目标

暂停改代码，用极简任务定位系统的真实能力边界。

## 动机

Step 11-24 连续 14 步迭代都在"修瓶颈→暴露新瓶颈"循环中。需要停下来回答：
系统缺的到底是参数、架构还是训练方法？

## 诊断 1: DA-STDP 裸机能力

三个极简任务，绕过 ClosedLoopAgent 复杂管线：

| 任务 | 设定 | 结果 | 判断 |
|------|------|------|------|
| 2-armed bandit | 2 个模式, A=80%奖励 | 权重 A=1.56>B=1.13 (Δ=+0.43), **但 accuracy=48%≈随机** | 权重能分化, 行为没跟上 |
| Contextual bandit | A→LEFT, B→RIGHT | 15.5% **< 25% chance**, improvement +2.3% | 条件关联基本没学会 |
| T-maze (1×3) | 食物固定在左 | food=71/500=14%, improvement +1% | 连 3 格世界都没学会 |

**关键发现: DA-STDP 能改变权重, 但权重变化没有转化为行为改善。**

## 诊断 2: IT 表征质量

注入 4 种场景 (food_L, food_R, danger_L, empty), 测量各视觉层响应:

```
Scene      | V1 fires | V2 fires | V4 fires | IT fires | dlPFC fires
-----------|----------|----------|----------|----------|----------
food_L     |      809 |      246 |       35 |        2 |        0
food_R     |     1679 |      713 |      315 |       94 |      234
danger_L   |     1711 |      730 |      319 |      121 |      782
empty      |     1672 |      719 |      326 |      113 |      751
```

**三个致命问题:**
1. **IT 无法区分食物和危险**: food/danger ratio = 0.40 (应该 >1.5)
2. **IT 无位置不变性**: food_L=2 fires vs food_R=94 fires (invariance = -0.92)
3. **food_L 信号衰减到 0**: V1=809 → V2=246 → V4=35 → IT=2 → dlPFC=0
   食物在左的信号在层级传播中消亡了

## 根因分析

```
问题 1: 权重→行为转化链断裂
  DA-STDP 改变 cortex→D1 权重 Δ=0.43
  但 D1 firing 对权重变化不敏感 (up-state drive=40 >> weight effect ~2)
  → 权重变了, D1 firing 模式几乎不变 → M1 选择不变

问题 2: 视觉层级是"衰减器"而非"抽象器"
  信号从 V1→V2→V4→IT 逐级衰减 (809→246→35→2)
  但不是逐级抽象 (food 和 empty 的 IT 响应差距 48 vs 113)
  原因: STDP 是无监督 Hebbian, 学的是"什么经常出现"(空=最常见→最强)
  不是"什么和奖励相关"(食物=少见→反而弱)

问题 3: 不对称位置响应
  food_L 从 V1=809 衰减到 IT=2 (消亡)
  food_R 从 V1=1679 衰减到 IT=94 (存活)
  原因: 随机初始化的突触权重对左右不对称, 没有通过学习纠正

结论: 系统有两个独立的根本问题
  A. DA-STDP "权重→行为" 增益太低 (架构问题: BG 耦合)
  B. 视觉层级是衰减器不是抽象器 (学习问题: 需要 DA 调制 STDP)
```

## 方向判断

| 路径 | 内容 | 判断 |
|------|------|------|
| A: 纵向深化 | 修 BG 耦合增益 + DA 调制视觉 STDP | **应该做, 针对诊断出的两个问题** |
| B: 降级任务 | T-maze 等极简任务 | **已做, 结果: 连极简任务都学不会** |
| C: 换学习机制 | e-prop / predictive coding credit | 不急, 先修架构问题 |

**具体下一步:**
1. 修 BG "权重→行为" 增益: 让权重 Δ=0.43 真正影响 D1 firing 偏好
2. 给视觉 STDP 加 DA 调制: 食物事件后增强 V2/V4 的 STDP → 学习奖励相关特征

## 回归测试: 30/30 CTest (含新增 minimal_tasks_tests)

## 系统状态

```
诊断完成. 两个根本问题定位:
  1. BG 权重→行为 增益太低 (权重变了但D1 firing不变)
  2. 视觉层级是衰减器不是抽象器 (食物信号在IT层消亡)
下一步: 修 BG 耦合增益 + DA 调制视觉 STDP (路径 A)
```
