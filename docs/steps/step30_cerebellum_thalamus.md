# Step 30: 小脑前向预测 + 丘脑门控 + Baldwin 重进化

> 日期: 2026-02-08
> 状态: ✅ 完成

## 目标

完成学习链路最后两环 (⑨小脑 ⑩丘脑)

## 小脑前向预测接入闭环

**生物学 (Yoshida et al. 2025, J Neuroscience):**
小脑和基底节协同强化学习。小脑预测动作的感觉后果，预测错误通过
climbing fiber 驱动 PF→PC LTD。比 DA 反馈快 10× (每步预测 vs 稀疏奖励)。

**实现 (信息量压缩: 275→24 神经元):**
```
GrC=12, PC=4(每方向1个), DCN=4, MLI=2, Golgi=2
投射: M1→CB(efference copy), V1→CB(视觉context), CB→MotorThal, CB→BG
CF误差: |last_reward| 作为 proxy (意外奖惩=预测失败)
```

**结果:**
- Learner advantage: +0.017 → +0.053 (3× 提升)
- 控制组 safety=0.02 vs 学习组 0.22 (CB 帮助回避危险)

## 丘脑 NE/ACh 门控

**生物学 (2024 Nature):**
高阶丘脑核选择性传递状态信息。NE/ACh 控制 TRN 兴奋性:
高 NE (警觉) → TRN 放松 → 更多信号通过; 低 NE → TRN 收紧 → 过滤。

**实现:**
```cpp
float trn_gate_drive = 3.0 * (1.0 - 0.5*NE - 0.5*ACh);
// NE=0.2 → gate=2.4 (正常), NE=0.5 → gate=1.5 (开放)
```

## Baldwin 重进化 (含小脑+丘脑)

100 代 × 60 个体 × 5 seed, 1000 步评估。进化中 (后台运行)。

进化发现的稳定趋势:
- `da_stdp_lr ≈ 0.005` (极低学习率: 慢慢学比快学好)
- `noise ≈ 70` (中等探索)
- `bg_gain ≈ 7` (小脑补充后 BG 不需要那么强)
- `lgn_gain ≈ 400-500` (高视觉增益)
- `replay ≈ 13-15` (大量重放巩固)

## 学习链路完成度: 10/10

```
① 感觉编码    V1→V2→V4→IT                    ✅
② 预测编码    L6预测 + mismatch STDP            ✅
③ 动作选择    dlPFC→BG D1/D2→丘脑→M1           ✅
④ 奖励信号    VTA DA burst/pause                ✅
⑤ DA-STDP     三因子 + 乘法增益                  ✅
⑥ 恐惧学习    杏仁核 one-shot                    ✅
⑦ 情景记忆    海马 CA3 + SWR 重放                ✅
⑧ 先天拓扑    Baldwin 进化 (100代跑中)           ✅
⑨ 小脑预测    CF-LTD + DCN→BG协同               ✅
⑩ 丘脑门控    NE/ACh→TRN excitability           ✅
```

## 当前瓶颈分析

学习链路结构完整，但泛化还不稳定:
- 泛化从 +0.667 (无小脑最优进化) 到 -0.10 (有小脑重新进化)
- 根因: 10 个系统的参数耦合，进化需要在联合空间找平衡点
- 泛化 ≠ 学习链路。泛化 = f(表征抽象度, 先天拓扑, 经验多样性)

## 系统状态

```
53区域 · ~144闭环神经元 (120+24小脑) · ~125投射
学习链路: 10/10 完整
学习能力: learner advantage +0.028~0.053
泛化: 待进化收敛后验证 (100代进化后台运行中)
速度: 2.5秒/6测试
下一步: 进化结果应用 → 泛化验证 → 规模扩展或间接编码
```
